{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bf043f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain openai \n",
    "# pip install TextBlob\n",
    "# pip install --upgrade --quiet  langchain-openai tiktoken chromadb langchain\n",
    "# pip install langchain_experimental\n",
    "# pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a53ade79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Source :https://www.analyticsvidhya.com/blog/2023/06/how-to-automate-data-analysis-with-langchain/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ddad436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import os \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "from langchain_experimental.agents import create_pandas_dataframe_agent \n",
    "from langchain.llms import OpenAI\n",
    "import json\n",
    "from pandas import json_normalize\n",
    "\n",
    "#setup the api key \n",
    "# os.environ['OPENAI_API_KEY']=\"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\" #Julien key\n",
    "os.environ['OPENAI_API_KEY']=\"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\" #Haythem key\n",
    "# os.environ['OPENAI_API_KEY']=\"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\" #Téo key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adbc1538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.info of                                 comment_id      customer_name  rating  \\\n",
      "4003  ed4a0da9-fa55-4ee1-afd1-90287709811c    Carolyn Heather       1   \n",
      "637   1e801994-80ce-4f06-9999-9e6199dd1388           customer       5   \n",
      "4434  179e2edf-266d-44c8-af9c-6c91be5a28dc         Dan Sipple       1   \n",
      "941   6be4f01d-1a93-4a8b-a0b3-2f6984d7b799  Vishal Shrivastav       5   \n",
      "373   7ea30ea3-751b-4615-98d7-53f5aedff2ca           customer       5   \n",
      "...                                    ...                ...     ...   \n",
      "3998  f21d26ff-ef4a-4dfc-a35f-a15a24e982e3             Regina       5   \n",
      "4000  1545dfff-57d1-4fad-8739-3c898e4ea398           customer       5   \n",
      "3999  66f2823b-45f2-4c94-9ec6-0a334dd5c645           customer       1   \n",
      "4001  c9259b4a-4d09-42f4-9cc4-f3124f8ccb48    Gerald Overholt       5   \n",
      "4002  1b19bb2f-587a-44c4-bc29-a81c6276318c                Ray       1   \n",
      "\n",
      "     verification_status customer_location  \\\n",
      "4003        not verified                US   \n",
      "637             Verified                US   \n",
      "4434        not verified                US   \n",
      "941         not verified                IN   \n",
      "373             Verified                US   \n",
      "...                  ...               ...   \n",
      "3998            Verified                US   \n",
      "4000            Verified                US   \n",
      "3999            Verified                US   \n",
      "4001        not verified                US   \n",
      "4002        not verified                US   \n",
      "\n",
      "                                comment_title  \\\n",
      "4003                  ｇ ｉ ｂ ｉ ｓ ｌ ａ ｗ ! ｎ ｆ ｏ   \n",
      "637             Worked with an amazing banker   \n",
      "4434             Customer service is terrible   \n",
      "941           This is the best website I know   \n",
      "373    Got me handled quickly and efficiently   \n",
      "...                                       ...   \n",
      "3998          Amazing and simple to use!!!!!!   \n",
      "4000                                     Rate   \n",
      "3999       Why do i have to load money to my…   \n",
      "4001  If you have kids and you are not using…   \n",
      "4002                                  BEWARE!   \n",
      "\n",
      "                                        comment_content comment_date  \\\n",
      "4003  Worst customer service and they hold you funds...   2024-03-13   \n",
      "637   Worked with an amazing banker, everything was ...   2024-03-12   \n",
      "4434  Customer service is terrible. Every person I t...   2024-03-12   \n",
      "941                    This is the best website I know    2024-03-12   \n",
      "373             Got me handled quickly and efficiently    2024-03-12   \n",
      "...                                                 ...          ...   \n",
      "3998                                               None   2020-02-16   \n",
      "4000                          Nice card and easy to use   2020-02-14   \n",
      "3999  Why do i have to load money to my. Gohenry acc...   2020-02-14   \n",
      "4001  If you have kids and you are not using Gohenry...   2020-02-09   \n",
      "4002  This is just a placeholder from this fraudulen...   2019-07-24   \n",
      "\n",
      "     comment_date_of_experience  company_response company_response_date  \\\n",
      "4003                 2024-03-12             False                  None   \n",
      "637                  2024-02-22             False                  None   \n",
      "4434                 2024-03-12             False                  None   \n",
      "941                  2024-03-12              True            2024-03-12   \n",
      "373                  2024-03-02             False                  None   \n",
      "...                         ...               ...                   ...   \n",
      "3998                 2020-02-16              True            2020-03-04   \n",
      "4000                 2020-02-14              True            2020-03-04   \n",
      "3999                 2020-02-14              True            2020-03-06   \n",
      "4001                 2020-02-09              True            2020-03-04   \n",
      "4002                 2019-07-24              True            2020-03-04   \n",
      "\n",
      "                               company_response_content  response_duration  \\\n",
      "4003                                               None                NaN   \n",
      "637                                                None                NaN   \n",
      "4434                                               None                NaN   \n",
      "941   Hi Vishal, thank you for your feedback and 5-s...                0.0   \n",
      "373                                                None                NaN   \n",
      "...                                                 ...                ...   \n",
      "3998  Hi Regina, thank you for taking the time to re...               17.0   \n",
      "4000  Hi, that's great to hear! If you come across a...               19.0   \n",
      "3999  In order to have a GH account, an adult over t...               21.0   \n",
      "4001  Hi Gerald, thank you ao much for your review! ...               24.0   \n",
      "4002  Hi Ray,  I can best answer your review by givi...              224.0   \n",
      "\n",
      "                    company_id                company_name  \n",
      "4003  65f17422a149b0031406e9df           Crypto Dispensers  \n",
      "637   65f17391a149b0031323e93a  Liberty First Credit Union  \n",
      "4434  65f1743fa149b0031406e9ed                    PNC Bank  \n",
      "941   65f1739ca149b0031406e9de           GoHenry by Acorns  \n",
      "373   65f17391a149b0031406e9dd  Liberty First Credit Union  \n",
      "...                        ...                         ...  \n",
      "3998  65f1739ca149b0031406e9de           GoHenry by Acorns  \n",
      "4000  65f1739ca149b0031406e9de           GoHenry by Acorns  \n",
      "3999  65f1739ca149b0031406e9de           GoHenry by Acorns  \n",
      "4001  65f1739ca149b0031406e9de           GoHenry by Acorns  \n",
      "4002  65f1739ca149b0031406e9de           GoHenry by Acorns  \n",
      "\n",
      "[4605 rows x 15 columns]>\n"
     ]
    }
   ],
   "source": [
    "# Importing the data\n",
    "df = pd.read_json('comments_to_analyse.json')\n",
    "# Initializing the agent \n",
    "\n",
    "df2 = df.sort_values('comment_date',ascending=False)\n",
    "print(df2.info)\n",
    "# display(df2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba87ede",
   "metadata": {},
   "source": [
    "# Script pour transferer un json ==> csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a2214a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON data successfully converted to CSV!\n"
     ]
    }
   ],
   "source": [
    "# Read JSON data from a file (replace 'data.json' with your actual file path)\n",
    "with open('comments.json', encoding='utf-8') as inputfile:\n",
    "    df = pd.read_json(inputfile)\n",
    "\n",
    "# Write the DataFrame to a CSV file (replace 'data.csv' with your desired output file path)\n",
    "df.to_csv('comments.csv', encoding=\"utf-8\", index=False)\n",
    "\n",
    "print(\"JSON data successfully converted to CSV!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8291bfe",
   "metadata": {},
   "source": [
    "# Model 1: Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9579099c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.llm import LLMChain\n",
    "# from langchain.prompts import PromptTemplate\n",
    "from langchain import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from math import *\n",
    "import time\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential,\n",
    ")  # for exponential backoff\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################## save_openAI_output_into_csv ############################## \n",
    "def save_openAI_output_into_csv(output):\n",
    "    # On initialise le dataframe qui récupérera le full output\n",
    "    columns = ['comment_id','company_id','Category','Nature','Analysis']\n",
    "    df_responses =pd.DataFrame(data=None, index=None, columns=columns, dtype=None, copy=None)\n",
    "\n",
    "    # On parcours l'output et on transforme le str contenu dans ['text'] en dataframe puis on le clean avant de l'ajouter dans df_responses\n",
    "    for i in range(len(output)):\n",
    "        dict = json.loads(output[i]['text'])\n",
    "        # print(\"----> dict \",i)\n",
    "        # print(dict,\"\\n\")\n",
    "        \n",
    "        if \"output\" in dict:\n",
    "            df_comment = json_normalize(dict['output'])\n",
    "            # print(\"----> dataframe\")\n",
    "            # print(df_comment,\"\\n\")\n",
    "        else:\n",
    "            df_comment = json_normalize(dict) \n",
    "            # print(\"----> dataframe without ouput\")\n",
    "            # print(df_comment,\"\\n\")\n",
    "\n",
    "        # On enleve les lignes ou l'IA a quand même indiqué une catégorie mais avec rien dedans\n",
    "        df_comment = df_comment.drop(df_comment[df_comment['Nature'] == 'not mentioned'].index)\n",
    "\n",
    "        # On ajoute à df_responses\n",
    "        df_responses  = pd.concat([df_responses, df_comment],ignore_index=True, sort=False)\n",
    "        \n",
    "    print(\"-----output----\")\n",
    "    display(df_responses)\n",
    "    \n",
    "    # append data frame to CSV file\n",
    "    df_responses.to_csv('comments_analyzed.csv', mode='a', index=False, header=False)\n",
    "    \n",
    "    print(\"-----saved to csv----\")\n",
    "    \n",
    "    return df_responses\n",
    "############################## /save_openAI_output_into_csv ##############################    \n",
    "\n",
    "\n",
    "\n",
    "############################## analyse_comment_with_openIA ##############################    \n",
    "# @retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
    "def analyse_comment_with_openIA(df_prompt):\n",
    "\n",
    "    # Define prompt 1\n",
    "    prompt_template1 = \"\"\"\n",
    "    As a marketing expert, you will analyse for each of these categories (delimited by <cat> </cat>) the following customer feedback: \"{text}\".\n",
    "    Each category analysis will begin by the nature of the comment (Is it positive, negative, not mentioned) and then concisely explain why but only if it's positive or negative.\n",
    "    The output should be in a JSON format (delimited by <json_format> </json_format>).\n",
    "    \n",
    "    <cat>\n",
    "        Usability,\n",
    "        Speed/Performance,\n",
    "        Pricing,\n",
    "        Customer Service,\n",
    "        Product Quality,\n",
    "        Billing/Invoicing,\n",
    "        Delivery/Shipping,\n",
    "        Communication,\n",
    "        Returns/Refunds,\n",
    "        Product Features/Functionality\n",
    "    </cat>\n",
    "    \n",
    "    <json_format>\n",
    "    output: [\n",
    "        Category: Category_name,\n",
    "        Nature: answer,\n",
    "        Analysis: answer\n",
    "        ]\n",
    "    </json_format>\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define prompt 2\n",
    "    prompt_template2 = \"\"\"\n",
    "    As a marketing expert, you will analyse the following customer feedback: \"{text}\".\n",
    "    You will identify which categories this feedback relates to and for each category the analysis will begin by the nature of the comment (Is it positive, negative, not mentioned) and then concisely explain why but only if it's positive or negative.\n",
    "    The output should be in a JSON format and you will label it with its comment_id: \"{comment_id}\" and its company_id: \"{company_id}\"\n",
    "    \n",
    "    <json_format>\n",
    "    [\n",
    "        output: [\n",
    "            comment_id: comment_id\n",
    "            company_id: company_id\n",
    "            Category: Category_name,\n",
    "            Nature: answer,\n",
    "            Analysis: answer\n",
    "            ]\n",
    "    ]\n",
    "    </json_format>\n",
    "    \"\"\"\n",
    "    prompt = PromptTemplate.from_template(prompt_template2)\n",
    "\n",
    "    # Define LLM chain\n",
    "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo-16k\")\n",
    "    llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "    print(\"----input----\")\n",
    "    display(df_prompt)\n",
    "    # On créé le tableau d'input\n",
    "    final_input = []\n",
    "    for i in df_prompt.index:\n",
    "        # Prepare the input for the chain\n",
    "        input = {'text': df_prompt.loc[i, \"comment_content\"], 'comment_id':df_prompt.loc[i,'comment_id'], 'company_id':df_prompt.loc[i,'company_id']}\n",
    "        final_input.append(input)\n",
    "    \n",
    "    # Run the chain\n",
    "    print(f'############################ => CHAIN RUNNING (Please wait) <= ############################ \\n')\n",
    "    output = llm_chain.batch(final_input)\n",
    "    # print(\"----final_input----\")\n",
    "    # print(final_input,\"\\n\")\n",
    "    # print(\"-----output----\")\n",
    "    # print(output,\"\\n\")\n",
    "\n",
    "    df_responses = save_openAI_output_into_csv(output)\n",
    "\n",
    "    return df_responses\n",
    "############################## /analyse_comment_with_openIA ##############################   \n",
    "\n",
    "\n",
    "def analyse_comment_with_openIA_single_request(df_prompt):\n",
    "\n",
    "    # Define prompt 1\n",
    "    prompt_template1 = \"\"\"\n",
    "    As a marketing expert, you will analyse for each of these categories (delimited by <cat> </cat>) the following customer feedback: \"{text}\".\n",
    "    Each category analysis will begin by the nature of the comment (Is it positive, negative, not mentioned) and then concisely explain why but only if it's positive or negative.\n",
    "    The output should be in a JSON format (delimited by <json_format> </json_format>).\n",
    "    \n",
    "    <cat>\n",
    "        Usability,\n",
    "        Speed/Performance,\n",
    "        Pricing,\n",
    "        Customer Service,\n",
    "        Product Quality,\n",
    "        Billing/Invoicing,\n",
    "        Delivery/Shipping,\n",
    "        Communication,\n",
    "        Returns/Refunds,\n",
    "        Product Features/Functionality\n",
    "    </cat>\n",
    "    \n",
    "    <json_format>\n",
    "    output: [\n",
    "        Category: Category_name,\n",
    "        Nature: answer,\n",
    "        Analysis: answer\n",
    "        ]\n",
    "    </json_format>\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Define prompt 2\n",
    "    prompt_template2 = \"\"\"\n",
    "    As a marketing expert, you will analyse the following customer feedback: \"{text}\".\n",
    "    You will identify which categories this feedback relates to and for each category the analysis will begin by the nature of the comment (Is it positive, negative, not mentioned) and then concisely explain why but only if it's positive or negative.\n",
    "    The output should be in a JSON format and you will label it with its comment_id: \"{comment_id}\" and its company_id: \"{company_id}\"\n",
    "    \n",
    "    <json_format>\n",
    "    [\n",
    "        output: [\n",
    "            comment_id: comment_id\n",
    "            company_id: company_id\n",
    "            Category: Category_name,\n",
    "            Nature: answer,\n",
    "            Analysis: answer\n",
    "            ]\n",
    "    ]\n",
    "    </json_format>\n",
    "    \"\"\"\n",
    "  #       Here are 10 pet chinchilla name ideas, in a json container, with numbered keys.\\n'\n",
    "  # 'Each json item has this form: key=\"<name_n>\", value = \"<generated_name>, '\n",
    "  # 'where `n` is the item number, and `value` has the funny name. \\n\\n{',\n",
    "\n",
    "     # and you will label it with its comment_id: \"{comment_id}\" and its company_id: \"{company_id}\"\n",
    "    # You have in input a List of customer feedbacks in the form of dictionnaries.\n",
    "\n",
    "        \n",
    "    # <json_format>\n",
    "    # [\n",
    "    #     output: [\n",
    "    #         comment_id: comment_id,\n",
    "    #         company_id: company_id,\n",
    "    #         Category: Category_name,\n",
    "    #         Nature: answer,\n",
    "    #         Analysis: answer\n",
    "    #         ]\n",
    "    # ]\n",
    "    # </json_format>\n",
    "\n",
    "\n",
    "    \n",
    "    # Define prompt 3\n",
    "    prompt_template3 = \"\"\"\n",
    "\n",
    "    As a marketing expert, you will analyse each customer feedbacks in the following array: \"{input}\".\n",
    "    This array contains customer feedbacks with the following format: [{'feedback': value, 'comment_id': value, 'company_id': value}]\n",
    "    For each feedback, you will identify which categories this feedback relates to.\n",
    "    For each category the analysis will begin by the nature of the comment (Is it positive, negative, not mentioned) and then concisely explain why but only if it's positive or negative.\n",
    "    Always answer in the following json format:\n",
    "    \n",
    "    [{comment_id:value, company_id:value, Category:value, Nature:value, Analysis:value}]\n",
    "    \n",
    "    ----------------------------------------\n",
    "    \n",
    "    ONLY JSON IS ALLOWED as an answer. No explanation or other text is allowed.\n",
    "\n",
    "    \"\"\"\n",
    "    prompt = PromptTemplate.from_template(prompt_template3)\n",
    "\n",
    "    # Define LLM chain\n",
    "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo-16k\")\n",
    "    llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "    print(\"----input----\")\n",
    "    display(df_prompt)\n",
    "    # On créé le tableau d'input\n",
    "    final_input = []\n",
    "    for i in df_prompt.index:\n",
    "        # Prepare the input for the chain\n",
    "        input = {'feedback': df_prompt.loc[i, \"comment_content\"], 'comment_id':df_prompt.loc[i,'comment_id'], 'company_id':df_prompt.loc[i,'company_id']}\n",
    "        final_input.append(input)\n",
    "\n",
    "    # Run the chain\n",
    "    print(f'############################ => CHAIN RUNNING (Please wait) <= ############################ \\n')\n",
    "    print(final_input)\n",
    "    final_input = json.dumps(final_input)\n",
    "    print(final_input)\n",
    "\n",
    "    input = {'input': final_input}\n",
    "    \n",
    "    output = llm_chain.run(input)\n",
    "    # print(\"----final_input----\")\n",
    "    # print(final_input,\"\\n\")\n",
    "    print(\"-----output----\")\n",
    "    print(output,\"\\n\")\n",
    "\n",
    "    # df_responses = save_openAI_output_into_csv(output)\n",
    "    df_responses = []\n",
    "    return df_responses\n",
    "############################## /analyse_comment_with_openIA ##############################\n",
    "\n",
    "\n",
    "############################## MAIN ##############################\n",
    "df\n",
    "\n",
    "\n",
    "# Variable servant à éviter l'erreur du rate limit\n",
    "rate_limit_per_minute = 3 # TODO\n",
    "batch_size = 3 # taille du batch (peut être modifié mais provoque une erreur venant d'OpenAI sur le rate limit quand >= 10)\n",
    "\n",
    "# On récupére seulement les fichiers qui n'ont pas été traité\n",
    "\n",
    "# initialisations des compteurs pour envoyer les requetes par batch\n",
    "length_df = len(df) # length of df\n",
    "nbr_of_batchs = ceil(len(df)/batch_size) # On calcul le nombre de batch à l'arrondi supérieur\n",
    "batch_counter = 1 #compteur pour debugging\n",
    "comment_counter = 0 #compteur pour debugging\n",
    "\n",
    "# Calculate the delay based on your rate limit\n",
    "\n",
    "delay_in_seconds = 60.0 / rate_limit_per_minute\n",
    "\n",
    "for i in range(nbr_of_batchs):\n",
    "    print(f'################################# => batch number: {i} <= #################################')\n",
    "    print(f'comment_counter: {comment_counter} & batch_size: {batch_size}')\n",
    "    \n",
    "    # On analyse les X comments et on les enregistre dans le fichier comments_analyzed.csv\n",
    "    df_responses = analyse_comment_with_openIA(df.iloc[comment_counter:comment_counter+batch_size, ])\n",
    "    # df_responses = analyse_comment_with_openIA_single_request(df.iloc[comment_counter:comment_counter+batch_size, ])\n",
    "    \n",
    "    # On mets à jour le champ analyzed des comments à True dans le fichier comments.json\n",
    "    # TODO => Faut il le faire ici après chaque batch avec df_responses['comments_id'] ou bien faut il attendre que tout les batchs soit fait\n",
    "\n",
    "    \n",
    "    # pour ensuite prendre le fichier comments_analyzed.csv,\n",
    "    # récupérer les comments_id unique et modifié la base de données elasticsearch\n",
    "    \n",
    "    # On incrémente batch_counter et comment_counter\n",
    "    batch_counter += 1\n",
    "    comment_counter += batch_size\n",
    "    \n",
    "    if i == 0:\n",
    "        break\n",
    "        \n",
    "    # Sleep for the delay\n",
    "    print(f'Sleep for: {delay_in_seconds}')\n",
    "    time.sleep(delay_in_seconds)\n",
    "\n",
    "############################## /MAIN ##############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9848bd0d-270e-4aa6-bb97-d6fc954816bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(comment_counter)\n",
    "# print(batch_size)\n",
    "# print(df.index)\n",
    "# df.iloc[comment_counter:comment_counter+batch_size, ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
